---
title: "Circle experiment parameter sweep."
author: "Jesse Leigh Patsolic"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    fig_height: 8
    fig_width: 8
    highlight: pygments
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_depth: 2
  keep_md: true

---

<style type="text/css">
.table {
    width: 40%;
}
tr:hover {background-color:#f5f5f5;}
</style>


```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
```

```{r, eval = FALSE, include = FALSE, echo = FALSE}
require(devtools)
#ref <- '5bce7519043640bba54867c4070df11af7c09d78'
#devtools::install_github('mrae/R-rerF', ref = ref)

rmarkdown::render("d_sweep.Rmd")
#system("sweeping_tests.Rmd")
```

```{r packages, include = FALSE, echo = FALSE}
require(ggplot2)
require(foreach)
require(grDevices)
require(rmarkdown)
require(rerf)
require(devtools)
require(doMC)
registerDoMC(6)
```


# Problem statment 

Consider a 100-gon where 10 vertices are colored 1 and
the rest are colored 0 according to the following rules: 

* Class 1 consists of two groups of 5 contiguous vertices colored 1.
* Class 2 consists of two groups of 6 and 4 contiguous vertices, respectively, colored 1.


## sampling toy data

We sample equally from the distributions described above and futher divide them 50/50 into training and testing sets. 

```{r sampling}
#set.seed(601)
set.seed(1234)
n <- 1/2 * c(400, 800, 2000, 4000)
c1 <- n
c2 <- n

samp <- function(c1,c2){
	X1 <- foreach(i = 1:sum(c1), .combine = rbind) %do% {
	  set.seed(i^2)
	  cir <- rep(0,100)
	
	  s1 <- sample(0:99, 1)
	  l1 <- s1:(s1 + 4) %% 100
	
	  s2 <- sample(setdiff(0:99, unique(c(l1, l1 - 4))), 1)
	  l2 <- s2:(s2 + 4) %% 100
	
	  cir[l1 + 1] <- 1
	  cir[l2 + 1] <- 1
	
	  cir
	}
	
	X2 <- foreach(i = 1:sum(c2), .combine = rbind) %do% {
	  set.seed(i^2)
	  cir <- rep(0,100)
	
	  s1 <- sample(0:99, 1)
	  l1 <- s1:(s1 + 5) %% 100
	
	  s2 <- sample(setdiff(0:99, unique(c(l1, l1 - 3))), 1)
	  l2 <- s2:(s2 + 3) %% 100
	
	  cir[l1 + 1] <- 1
	  cir[l2 + 1] <- 1
	
	  cir
	}
	X <- as.matrix(rbind(X1, X2))
	rownames(X) <- NULL
	return(X)
}

X <- mapply(samp, c1, c2)
Y  <- mapply(function(x,y) c(rep(0, x), rep(1, y)), c1,c2)


set.seed(1030)
strain <- lapply(X, function(x) sort(sample(nrow(x), floor(nrow(x)/2))))

Xtrain <- mapply(function(x,s) x[s, ], X, strain)
Ytrain <- mapply(function(y,s) y[s], Y, strain)

stest <- mapply(function(x,s) setdiff(1:nrow(x), s), X, strain)

Xtest <- mapply(function(x,s) x[s, ], X, stest)
Ytest <- mapply(function(y,s) y[s], Y, stest)
```


# Running R-Rerf

We have created samples of size `r n` respectively and will run structured
random forest on half and test on the rest. 

```{r run-rf}
p <- 100
d <- c(1, 5, seq(20,100, by = 20))
iw <- 100
ih <- 1

mw <- 2L
Mw <- 15L

#pm <- c(2,8,16)
pm <- mw:Mw

rectMM <- expand.grid(p.max = pm, d = d)

opt.list <- lapply(1:nrow(rectMM), 
			  function(i) { 
				  list(p = p, d = rectMM[i,2], 
				       "image-patch-rectangles", 
				       iw = iw, ih = ih, 
				       patch.min = 1L, 
               patch.max = rectMM[i,1]) 
        }
        )
```



```{r}
run1 <- 
  foreach(xi = 1:length(Xtrain), .combine = rbind) %:% 
  foreach(oi = opt.list, .combine = rbind) %dopar% {
  forest <- RerF(Xtrain[[xi]], Ytrain[[xi]], 
		 store.oob = TRUE,
		 num.cores = 1L, mat.options = oi, seed = 1L) 
  
  oob.predictions <- OOBPredict(Xtrain[[xi]], forest, num.cores = 1L)
  oob.error.rate <- mean(oob.predictions != Ytrain[[xi]])

  training.predictions <- Predict(Xtrain[[xi]], forest, num.cores = 1L)
  training.error.rate <- mean(training.predictions != Ytrain[[xi]])

  testing.predictions <- Predict(Xtest[[xi]], forest, num.cores = 1L)
  testing.error.rate <- mean(testing.predictions != Ytest[[xi]])

  data.frame(
       n = n[xi],
       d = oi$d,
       patch.max = oi$patch.max,
       #forest = forest, 
       oob.error = oob.error.rate,
       training.error = training.error.rate,
       testing.error = testing.error.rate)
       #oob.pred  = oob.predictions, 
       #training.pred = training.predictions,
       #test.pred = testing.predictions)
}
```

## Results

Below are the results of each run sweeping over $w \in [2,15]$ for each of the $n$.
Horizontal lines are plotted at 0.05 and 0.01.

```{r ggplot, fig.width = 8, fig.height = 8}
p1 <- ggplot(data = run1, aes(x = patch.max)) + 
	scale_y_log10() + 
	geom_point(aes(y = oob.error, col = "oob.error", shape = "oob.error"), alpha = 0.75) + 
	geom_point(aes(y = training.error, col = "train", shape = "train"), alpha = 0.75) + 
	geom_point(aes(y = testing.error, col = "test", shape = "test"), alpha = 0.75) + 
	geom_hline(yintercept = c(0.01, 0.05), size = 0.1, colour = 'gray10') + 
	#geom_point(alpha = 0.65, aes(shape = as.factor(n))) + 
	facet_grid(n ~ d, labeller = labeller(n = label_both, d = label_both))
#print(p1)
pdf("Rplots.pdf", w=12,h = 8)
p1  + guides(col = guide_legend())
dev.off()
```



```{r, include = FALSE, echo = FALSE}
pdf('plot1.pdf', height = 8, width = 14)
print(p1)
dev.off()
mtab <- sapply(n, function(nt) {
       tmp <- which.min(run1[run1$n == nt, ]$testing.error)
       identity(run1[run1$n == nt, ][tmp,])
		   })
```

### Best $\hat{L}$	
```{r, results = 'asis'}
knitr::kable(t(mtab))
```

# Using ts-patch options 

```{r rf-params}
p <- 100
d <- seq(20,100, by = 20)

rectMM <- expand.grid(p.min = 2L:15L, p.max = 2L:15L, d = d)
rectMM <- rectMM[rectMM$p.min < rectMM$p.max,]

opt.list2 <- lapply(1:nrow(rectMM), 
			  function(i) { 
				  list(p = p, d = rectMM[i, 3], 
				       "ts-patch", 
				       patch.min = rectMM[i, 1], 
               patch.max = rectMM[i, 2]) 
        }
        )

```

```{r}
run2 <- 
  foreach(xi = 1:length(Xtrain), .combine = rbind) %:% 
  foreach(oi = opt.list2, .combine = rbind) %dopar% {
  forest <- RerF(Xtrain[[xi]], Ytrain[[xi]], 
		 store.oob = TRUE,
		 num.cores = 1L, mat.options = oi, seed = 1L) 
  
  oob.predictions <- OOBPredict(Xtrain[[xi]], forest, num.cores = 1L)
  oob.error.rate <- mean(oob.predictions != Ytrain[[xi]])

  training.predictions <- Predict(Xtrain[[xi]], forest, num.cores = 1L)
  training.error.rate <- mean(training.predictions != Ytrain[[xi]])

  testing.predictions <- Predict(Xtest[[xi]], forest, num.cores = 1L)
  testing.error.rate <- mean(testing.predictions != Ytest[[xi]])

  data.frame(
       n = n[xi],
       d = oi$d,
       patch.max = oi$patch.max,
       patch.min = oi$patch.min,
       oob.error = oob.error.rate,
       training.error = training.error.rate,
       testing.error = testing.error.rate)

}
```

## Results

Below are the results of each run sweeping over $w \in [2,15]$ for each of the $n$.
Horizontal lines are plotted at 0.05 and 0.01.

```{r ggplot-2, fig.width = 8, fig.height = 8}
p2 <- ggplot(data = run2, aes(x = patch.max)) + 
	scale_y_log10() + 
	#geom_point(aes(y = oob.error, col = "oob.error", shape = "oob.error"), alpha = 0.75) + 
	#geom_point(aes(y = training.error, col = "train", shape = "train"), alpha = 0.75) + 
	#geom_point(aes(y = testing.error, col = "test", shape = "test"), alpha = 0.75) + 
	geom_hline(yintercept = c(0.01, 0.05), size = 0.1, colour = 'gray10') + 
	geom_point(aes(y = testing.error, col = "testing.error", shape = "testing.error"), alpha = 0.75) + 
	geom_point(aes(y = training.error, col = "training.error", shape = "training.error"), alpha = 0.75) + 
	geom_point(aes(y = oob.error, col = "oob.error", shape = "oob.error"), alpha = 0.75) + 
	facet_grid(patch.min ~ d + n, labeller = labeller(n = label_both, d = label_both))

print(p2)
```


```{r, fig.width = 8, fig.height = 12}
p3.testing <- 
  ggplot(data = run2,
             aes(x = patch.min, y = patch.max)) + 
       geom_raster(aes(fill = testing.error)) + 
       scale_fill_gradient2(
         low  = "#006600", 
         mid  = "white", 
         high = "#000000", 
         midpoint = log10(0.05), 
         trans = 'log10',
         breaks = c(0.001, 0.05, 0.01,0.1,1)) + 
       facet_grid(d ~ n, labeller = labeller(d = label_both, n = label_both))

p3.training <- 
  ggplot(data = run2,
             aes(x = patch.min, y = patch.max)) + 
       geom_raster(aes(fill = training.error)) + 
       scale_fill_gradient2(
         low  = "#006600", 
         mid  = "white", 
         high = "#000000", 
         midpoint = log10(0.05), 
         trans = 'log10',
         breaks = c(0.001, 0.05, 0.01,0.1,1)) + 
       facet_grid(d ~ n, labeller = labeller(d = label_both, n = label_both))

p3.oob <- 
  ggplot(data = run2,
             aes(x = patch.min, y = patch.max)) + 
       geom_raster(aes(fill = oob.error)) + 
       scale_fill_gradient2(
         low  = "#006600", 
         mid  = "white", 
         high = "#000000", 
         midpoint = log10(0.05), 
         trans = 'log10',
         breaks = c(0.001, 0.05, 0.01,0.1,1)) + 
       facet_grid(d ~ n, labeller = labeller(d = label_both, n = label_both))

show(gridExtra::grid.arrange(p3.training, p3.oob, p3.testing))
```

## Min testing error 

```{r, include = FALSE, echo = FALSE}
mtab2 <- sapply(n, function(nt) {
       tmp1 <- which.min(run2[run2$n == nt, ]$testing.error)
       tmp2 <- which.min(run2[run2$n == nt, ]$training.error)
       tmp3 <- which.min(run2[run2$n == nt, ]$oob.error)
       run2[run2$n == nt, ][c(tmp1,tmp2,tmp3),]
		   })
```

### Best $\hat{L}$	
```{r, results = 'asis'}
knitr::kable(t(mtab2))
```




